<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Lars Hofmann" />

<meta name="date" content="2018-04-01" />

<title>Big Data mit R Desktop?</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/sandstone.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}

.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Lars Hofmann</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-fort-awesome"></span>
     
    Basis
  </a>
</li>
<li>
  <a href="about.html">
    <span class="fa fa-child"></span>
     
    Über
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-terminal"></span>
     
    R zählmalwas
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">R schaffen</li>
    <li>
      <a href="Rbigdata.html">2018-04-01 R-Big Data</a>
    </li>
    <li>
      <a href="wordcloud.html">2018-03-15 Word Cloud</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">R lernen @coursera</li>
    <li>
      <a href="pga_rr.html">2018-03-04 NOAA Storm Database</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/kundex">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://www.xing.com/profile/Lars_Hofmann16">
    <span class="fa fa-xing"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Big Data mit R Desktop?</h1>
<h4 class="author"><em>Lars Hofmann</em></h4>
<h4 class="date"><em>2018-04-01</em></h4>

</div>


<div id="grenzbestimmung" class="section level1">
<h1>Grenzbestimmung</h1>
<p><strong>Big Data</strong> — oder <strong>Neue digitale Daten</strong>, wie es in der deutschen amtlichen Statistik heißt — sind nicht erst seit heute in vieler Munde. Große Datenmengen in diesem Sinne bedeuten eine immense Hochskalierung von Speichern, Methoden und Werkzeugen gegenüber “traditionellen” Datenmengen. Nun beschäftige ich mich hier nicht mit neueren Big Data-Frameworks oder Cloud Computing, sondern eher mit kleinskaligen, “normalen” R-Geschichten. Mich interessiert also, wo so ungefähr die Grenze verläuft — von Big Data für “normale” Nutzer, die sich mit R und Statistik beschäftigen.</p>
<p>Im <em>normalen</em> Desktop-Gebrauch von R mit RStudio, d. h. ohne Client-Server-Architektur oder Cloud Computing, werden alle Prozesse im Hautspeicher (RAM) erledigt. Alle Importdaten, R-Objekte, sowie die für die Ergebnisse benötigten Rechenkapazitäten nehmen als <code>R Environments</code> diesen Hauptspeicher ein. Doch dieser ist auch bei modernen Rechnern begrenzt.</p>
<p>Ich arbeite mit einem recht modernen, trotzdem handelsüblichen Laptop:</p>
<ul>
<li>Ubuntu-Betriebssystem 64 bit</li>
<li>Intel i7-6700HQ mit 2,60GHz</li>
<li>16 GByte RAM</li>
<li>schnelle SSD-Festplatte</li>
</ul>
<p>Eins vorweg: Wie sich schon aus dem Gesagten ergibt, ist der RAM das ausschlaggebende Nadelöhr. Die vorgestellten Ergebnisse lassen sich wahrscheinlich allein mit diesem Einflussfaktor linear hochrechnen.</p>
<hr />
</div>
<div id="datenbeschaffung" class="section level1">
<h1>Datenbeschaffung</h1>
<p>Zunächst benötigen wir eine “Big Open Data”-Quelle. Im deutschsprachigem Raum gar nicht so einfach. Ohne langes Suchen nutze ich eine Quelle der American Statistical Association (ASA), die große offene Daten zu <a href="http://stat-computing.org/dataexpo/2009/the-data.html">Airline On-Time Statistics and Delay Causes</a> bereitstellt. In der Kurzbeschreibung heißt es:</p>
<blockquote>
<p>The data consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. This is a large dataset: there are nearly 120 million records in total, and takes up 1.6 gigabytes of space compressed and 12 gigabytes when uncompressed.</p>
</blockquote>
<p>Es handelt sich also um Daten zu <strong>allen (!)</strong> kommerziellen US-amerikanischen Inlandflügen in gut 20 Jahren. Aufgrund dieser Masse beschränken wir uns auf einen Ausschnitt von 2003 bis 2008, also einen Zeitraum von sechs Jahren (…ja, ich habe es mit allen versucht…).</p>
<p>Die Daten sind bz2-komprimiert nach Jahren verfügbar (Kompressionsfaktor: ~6) und werden mit dem folgenden R-Code beschafft. Das Gesamtvolumen beträgt ca. 0,67 GByte (komprimiert) bzw. ca. 4,00 GByte (Rohdaten). Um unnötige Downloads zu vermeiden, wird grundsätzlich mit <code>file.exists</code> geprüft, ob benötigte Eingangsdateien in dem zugewiesenen Unterordner <code>daten</code> bereits vorhanden sind. Fehlende Dateien werden anschließend heruntergeladen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2003</span><span class="op">:</span><span class="dv">2008</span>){
  <span class="cf">if</span>(<span class="op">!</span><span class="kw">file.exists</span>(<span class="kw">paste</span>(<span class="st">&quot;daten/&quot;</span>,i,<span class="st">&quot;.csv.bz2&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;&quot;</span>))){
    url &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;http://stat-computing.org/dataexpo/2009/&quot;</span>,i,<span class="st">&quot;.csv.bz2&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
    <span class="kw">download.file</span>(url, <span class="dt">destfile =</span> <span class="kw">paste</span>(<span class="st">&quot;daten/&quot;</span>,i,<span class="st">&quot;.csv.bz2&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
    }
}</code></pre></div>
<p>Die Dateigröße gibt uns eine erste Einordnung, wo die Grenze der Nutzbarkeit von Big Data auf normalen Laptop/PC-Systemen grob liegt: im <strong>GByte-Bereich</strong>. Wer “richtig” Big Data macht, bewegt sich eher im Terabyte-Bereich (1 TByte = 1.024 GByte) oder gar im Petabyte-Bereich (1 PByte = 1.024 TByte = 1.048.576 GigaByte).</p>
<hr />
<div id="kurzer-gedanke-zur-datendichte" class="section level2">
<h2>Kurzer Gedanke zur Datendichte</h2>
<p>Als<code>Datendichte</code> bezeichne ich den theoretischen Wert aus dem <strong>Verhältnis von Information und Overhead</strong>. Die Information ist der konkrete Datenwert, der Overhead ist alles andere, was Platz belegt (Metadaten, Trennzeichen). Hier ein rudimentäres Beispiel:</p>
<p><strong>CSV-Datei</strong></p>
<p><code>ID;Jahr;Alter;Religion;Anzahl</code><br />
<code>1;2018;35;2;500</code></p>
<p>Die reine Information ist <code>2018</code>, <code>35</code>, <code>2</code> und <code>500</code>. Alle anderen Zeichen sind in diesem Sinne der Overhead.</p>
<p>Betrachten wir mit diesem Beispiel einige andere typische Datenformate und deren Overhead:</p>
<p><strong>YAML-Datei</strong> (“YAML Ain’t Markup Language”)</p>
<p><code>---</code><br />
<code>ID: 1</code><br />
<code>Jahr: 2018</code><br />
<code>Alter: 35</code><br />
<code>Religion: 2</code><br />
<code>Anzahl: 500</code></p>
<p><strong>JSON-Datei</strong> (“JavaScript Object Notation”)</p>
<p><code>{</code><br />
<code>&quot;ID&quot;: 1,</code><br />
<code>&quot;Jahr&quot;: &quot;2018&quot;,</code><br />
<code>&quot;Alter&quot;: 35,</code><br />
<code>&quot;Religion&quot;: 2,</code><br />
<code>&quot;Anzahl&quot;: 500</code><br />
<code>}</code></p>
<p><strong>XML-Datei</strong> (“Extensible Markup Language”)</p>
<p><code>&lt;ID&gt;1&lt;/ID&gt;</code><br />
<code>&lt;Jahr&gt;2018&lt;/Jahr&gt;</code><br />
<code>&lt;Alter&gt;35&lt;/Alter&gt;</code><br />
<code>&lt;Religion&gt;2&lt;/Religion&gt;</code><br />
<code>&lt;Anzahl&gt;500&lt;/Anzahl&gt;</code></p>
<ul>
<li>CSV: 44 Zeichen mit Kopfzeile, 15 Zeichen ohne Kopfzeile</li>
<li>YAML: 49 Zeichen</li>
<li>JSON: 64 Zeichen</li>
<li>XML: 90 Zeichen</li>
</ul>
<p>Die Liste ist nach zunehmender Zeichenanzahl bei gleichem Informationsinhalt, also nach abnehmender <em>Datendichte</em> sortiert. Es ist daraus zu schließen, dass <em>auf Zeichenebene</em> im Beispiel das CSV-Format im Vergleich zum XML-Format nur ein Siebtel des Platzes bei gleichem Informationsinhalt benötigt (die Kopfzeile ist nur einmal deklariert und daher vernachlässigbar).</p>
<p>Natürlich greift dieser Vergleich sehr kurz; die Vorteile und Anwendungsmöglichkeiten der jeweiligen Datenformate ist hier nicht das Thema. Für meine Zwecke zählt an dieser Stelle nur, dass die verwendeten Eingangsdaten in CSV bei begrenzten Ressourcen ein Maximum an Datendichte bzw. an Informationsmenge beinhalten.</p>
<hr />
</div>
<div id="r-base-vs.tidyverse" class="section level2">
<h2>R Base vs. Tidyverse</h2>
<p>Ich vergleiche drei Methoden miteinander:</p>
<ul>
<li>die R Base-Methode <code>read.csv</code>,</li>
<li>die optimierte Methode <code>read_csv</code> aus der <code>Tidyverse</code>-Paketsammlung mit der optimierten <code>map_df</code>-Funktion des sogenannten <em>functional programming toolkits</em> <code>purrr</code>, und</li>
<li>die gleiche optimierte Methode, aber mit direkter Anwendung der <code>bind_rows</code>-Funktion (die auch von <code>map_df</code> genutzt wird)</li>
</ul>
<p>Alle drei Methoden können komprimmierte Rohdaten (z. B. “.zip” oder “.bz2”) direkt entpacken und einlesen. Leider ist das kein unerheblicher Aufwand, der eine Menge Laufzeit frisst. Es läge also nahe, die Dekompression vorzulagern, was wiederum hinsichtlich Reproduzierbarkeit nachteilig ist. Ich vergleiche darum alle Methoden mit und ohne Dekompression, zeige aber nur den kompakteren und reproduzierbaren Code mit der komprimierten Variante der Rohdaten.</p>
<p>Die nach <code>test_import</code> importierten Daten müssen nach jedem Vorgang mit <code>rm()</code> gelöscht werden, um den RAM frei zu machen. Alle Variablen werden auf den Datentyp <code>character</code> fixiert. Das erfordert den minimalen Importaufwand, weil die Daten nicht umformatiert werden müssen. Ohne diesen Schritt würden <em>alle</em> Methoden aufgrund der Datenmenge beim “Rowbinding” mit Fehlern abbrechen.</p>
<p>Die Laufzeit wird wie üblich mit der Funktion <code>system.time</code> unter Einsatz eines einfachen Zählers <code>x</code> gemessen. Der gekapselte Code dazwischen ist sozusagen der Prozess, dessen Laufzeit gemessen wird.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>({
  test_import &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;daten&quot;</span>, <span class="dt">full.names =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">lapply</span>(read.csv, <span class="dt">colClasses =</span> <span class="st">&quot;character&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>bind_rows
  x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x))  x[i] &lt;-<span class="st"> </span>x[i]<span class="op">+</span><span class="dv">1</span>
  })

<span class="kw">rm</span>(test_import)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">import_func &lt;-<span class="st"> </span><span class="cf">function</span>(dat) {
    <span class="kw">read_csv</span>(dat, <span class="dt">col_types =</span> <span class="kw">cols</span>(<span class="dt">.default =</span> <span class="kw">col_character</span>()))
}

<span class="kw">system.time</span>({
  test_import &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="st">&quot;daten&quot;</span>, <span class="dt">full.names =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">import_func</span>(.))
  x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x))  x[i] &lt;-<span class="st"> </span>x[i]<span class="op">+</span><span class="dv">1</span>
  })

<span class="kw">rm</span>(test_import)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>({
  test_import &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;daten&quot;</span>, <span class="dt">full.names =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">lapply</span>(read_csv, <span class="dt">col_types =</span> <span class="kw">cols</span>(<span class="dt">.default =</span> <span class="kw">col_character</span>())) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>bind_rows
  x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(x))  x[i] &lt;-<span class="st"> </span>x[i]<span class="op">+</span><span class="dv">1</span>
  })

<span class="kw">dim</span>(test_import)</code></pre></div>
<hr />
</div>
</div>
<div id="testergebnisse" class="section level1">
<h1>Testergebnisse</h1>
<p>Es werden in jedem Importprozess 42.363.271 Datenzeilen mit je 29 Variablen, also insgesamt <strong>1.228.534.859 (~ 1,2 Mrd.) Werte</strong> eingelesen. Die Speicherauslastung kommt dabei auf jeweils über 95 % bei 16 GByte RAM. Die Spitze wird nach dem Einlesen im Prozess des “Rowbindings” erreicht. In dem genutzten technischen Setting bilden die sechs genutzten Dateien die physikalische Grenze der verarbeitbaren Datenmenge. Die Ergebnisse der Laufzeitmessung sind wie folgt:</p>
<table>
<thead>
<tr class="header">
<th>Methode</th>
<th>komprimiert (ja/nein)</th>
<th>Laufzeit (sek)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>read.csv</td>
<td>ja</td>
<td>1011</td>
</tr>
<tr class="even">
<td>read_csv mit map_df</td>
<td>ja</td>
<td>511</td>
</tr>
<tr class="odd">
<td>read_csv mit bind_rows</td>
<td>ja</td>
<td>491</td>
</tr>
<tr class="even">
<td>read.csv</td>
<td>nein</td>
<td>383</td>
</tr>
<tr class="odd">
<td>read_csv mit map_df</td>
<td>nein</td>
<td>211</td>
</tr>
<tr class="even">
<td>read_csv mit bind_rows</td>
<td>nein</td>
<td>205</td>
</tr>
</tbody>
</table>
<p>Anschließend möchte ich testen, wie R mit diesem <em>Riesen-Tibble</em> umgehen kann. Ich stelle eine einfache Auswertung in der folgenden Tabelle dar. Das Tibble wird hierfür nach <code>Year</code> gruppiert und anschließend nach zwei Merkmalen ausgewertet: die Anzahl der eingesetzten Flugzeuge nach eindeutiger Tail Number <code>n_distinct(TailNum)</code> sowie die jährliche Gesamtzahl der Flüge <code>n()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(
  test_import <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">group_by</span>(Year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="kw">n_distinct</span>(TailNum), <span class="kw">n</span>()), 
  <span class="dt">format.args =</span> <span class="kw">list</span>(<span class="dt">decimal.mark =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">big.mark =</span> <span class="st">&quot;.&quot;</span>), 
  <span class="dt">caption =</span> <span class="st">&quot;Zusammenfassung der Anzahl der eingesetzten Flugzeuge nach eindeutiger Tail Number sowie jährliche Gesamtzahl der Flüge&quot;)</span></code></pre></div>
<hr />
</div>
<div id="fazit" class="section level1">
<h1>Fazit</h1>
<p>Mit einem cleveren Management von Im-/Export und den geeigneten Methoden/R-Paketen können auch mit R-Desktop Big Data-Probleme in einer begrenzten Größenordnung angegangen werden. Je größer die Datenmenge, desto wichtiger ist das genutzte Datenformat hinsichtlich Dateigröße und Parsing-Aufwand. Auf einen Formatvergleich in der Verarbeitung habe ich hier verzichtet. Vielleicht teste ich das später einmal aus.</p>
<p>Die optimierte Methode <code>read_csv</code> ist gegenüber der Basismethode <code>read.csv</code> weitaus effizienter. Der CSV-Import läuft in fast der doppelten Geschwindigkeit ab. Kommt der Dekomprimierungsprozess beim Import hinzu, läuft die optimierte Variante sogar mehr als doppelt so schnell. Der “funktionalere Ansatz” mit <code>map_df</code> ist gegenüber <code>lapply</code> / <code>bind_rows</code> leicht unterlegen, aber vergleichbar effizient.</p>
<p>Sind die Daten erst einmal als Tibble eingelesen, laufen einfache Analysefunktionen (z. B. <code>n()</code> oder <code>sum()</code>) und Gruppierungen mit <code>group_by()</code> erstaunlich effizient ab. Es spielt hier keine spürbare Rolle, wie groß der betrachtete Datensatz ist. Mit der Weiterverarbeitung von “Big Data mit R Desktop” will ich mich später bei Gelegenheit vertiefend beschäftigen…</p>
</div>
<div id="anhang-build-with" class="section level1">
<h1>Anhang: Build with</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.4.4 (2018-03-15)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 16.04.4 LTS
## 
## Matrix products: default
## BLAS: /usr/lib/libblas/libblas.so.3.6.0
## LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
## 
## locale:
##  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    
##  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   
##  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] svglite_1.2.1      wordcloud_2.5      RColorBrewer_1.1-2
##  [4] forcats_0.2.0      stringr_1.2.0      dplyr_0.7.4       
##  [7] purrr_0.2.4        readr_1.1.1        tidyr_0.8.0       
## [10] tibble_1.4.2       ggplot2_2.2.1      tidyverse_1.2.1   
## 
## loaded via a namespace (and not attached):
##  [1] slam_0.1-42      reshape2_1.4.3   haven_1.1.1      lattice_0.20-35 
##  [5] colorspace_1.3-2 htmltools_0.3.6  yaml_2.1.15      utf8_1.1.3      
##  [9] rlang_0.1.6      pillar_1.1.0     foreign_0.8-69   glue_1.2.0      
## [13] gdtools_0.1.7    modelr_0.1.1     readxl_1.0.0     bindrcpp_0.2    
## [17] bindr_0.1        plyr_1.8.4       munsell_0.4.3    gtable_0.2.0    
## [21] cellranger_1.1.0 rvest_0.3.2      psych_1.7.8      evaluate_0.10.1 
## [25] knitr_1.19       parallel_3.4.4   highr_0.6        broom_0.4.3     
## [29] tufte_0.3        Rcpp_0.12.15     scales_0.5.0     backports_1.1.2 
## [33] jsonlite_1.5     mnormt_1.5-5     hms_0.4.1        digest_0.6.12   
## [37] stringi_1.1.6    grid_3.4.4       rprojroot_1.3-2  cli_1.0.0       
## [41] tools_3.4.4      magrittr_1.5     lazyeval_0.2.1   crayon_1.3.4    
## [45] pkgconfig_2.0.1  xml2_1.2.0       lubridate_1.7.2  assertthat_0.2.0
## [49] rmarkdown_1.8    httr_1.3.1       rstudioapi_0.7   R6_2.2.2        
## [53] nlme_3.1-131.1   compiler_3.4.4</code></pre>
</div>

<p><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a><br />Dieses Werk ist lizenziert unter einer <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
